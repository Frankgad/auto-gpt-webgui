version: '3.9'
services:
  proxy:
    image: nginx:alpine
    restart: always
    ports:
      - 2222:2222
    hostname: nginx
    volumes:
      # - "./nginx.conf:/etc/nginx/nginx.conf"
      - ./nginx.tmpl:/etc/nginx/nginx.conf.template
    depends_on:
      - frontend
    healthcheck:
      test: curl -sS http://localhost:2222/
      interval: 60s
      retries: 3
      start_period: 2s
      timeout: 2s
    # cap_drop:
    #   - ALL
    privileged: false
    ipc: private
    # user: "xxx:xxx"   
    tmpfs:
     - /run/nginx:size=5M,mode=1777,noexec
     - /var/lib/nginx/tmp:size=60M,mode=1777,noexec
    environment:
      - "BACKEND_URL=${BACKEND_URL}"
    command: /bin/bash -c "envsubst < /etc/nginx/nginx.conf.template > /etc/nginx/nginx.conf && nginx -g 'daemon off;'"
    # read_only: true
  frontend:
    deploy:
      resources:
        limits:
          cpus: "4"
          memory: 2G
    image: ghcr.io/frankgad/auto-gpt-webgui
    restart: always
    ports:
      - 7070:7070
    environment:
      - "BACKEND_URL=http://${BACKEND_URL}:2222"
      - "MEMORY_BACKEND=redis"
      - "REDIS_HOST=redis"
      - "SMART_LLM_MODEL=gpt-3.5-turbo"
  redis:
    image: "redis/redis-stack-server:latest"